Method Validation in R -- Reference Range
========================================================
author: Daniel S. Herman, Niklas Krumm
date: July 2018
autosize: true
css: assets/custom.css

Overview
========================================================

In this section we will walk through examples of how to use R to analyze standard method validation experiments, beginning with reference range evaluation. 

- We will use real data acquired as part of a method transition for immunoassays (unconjugated estriol, alpha fetoprotein, and inhibin-A) used for prenatal risk assessment for Trisomy 21, Trisomy 18, and open neural tube defects.

- Relatively "clean" data has already been organized in separate tabs in an excel document. 

How to load data?
========================================================

- Let's first look at these datasets in our spreadsheet program.
- Now, let's load one of these data sets using the `read_excel` function

```{r, echo=FALSE, fig.align="center", out.width = "600px"}
knitr::include_graphics("assets/read_excel.png")
```

How does read_excel work?
========================================================
Click the green arrow to execute this code chunk:

```{r explore_function, eval=FALSE}
?read_excel
```

Example: Load Method Evaluation Data
========================================================
class: small-code

```{r example_data_load}
library(readxl)
uE3 <- read_excel(path="data/Method_Validation.data.xlsx", 
                sheet="MS uE3")
head(uE3)  # Take a peak
```

Exercise 1
========================================================
Load in the alpha fetoprotein (AFP) method comparison data into a tibble named `afp`

```{r load_data_1, echo=FALSE, include=FALSE}
afp <- read_excel(path="data/Method_Validation.data.xlsx", 
                sheet="MS AFP")
afp
```

```{r, eval=FALSE}
afp <- read_excel(path="XXXXXXXXXXXXX", 
                sheet="XXXXXXXXXXXX")
afp
```

```{r, echo=FALSE, fig.align="center", out.width = "500px"}
knitr::include_graphics("assets/read_excel.png")
```

More on data importing
========================================================
What about reading other sorts of data? [Check out the R **cheat sheet** specifically for importing data](https://github.com/rstudio/cheatsheets/raw/master/data-import.pdf).

Other cheat sheets exist as well, [check them out here](https://www.rstudio.com/resources/cheatsheets/)

Viewing data tables
========================================================

QC data import
========================================================
Once you have loaded some data into an R object (in this case, `afp`), you should always briefly visually and manually inspect it. Things to check for include:

 - Did the variable names import properly?  [Need to be able to refer to each variable]
 - Did variables get split appropriately [Do we have the right number of columns?]
 - Did any lines (observations) get skipped? Did the entire file get loaded?

View imported data - 1
========================================================
Let's next take a look at the data we have now saved as `afp`. We can do this in a few different ways.

```{r}
afp
```

- Note that it looks very similar to its original form in Excel. There are 3 columns and 161 rows. Each column has a specfic data format (`chr`, `dbl`, etc.). The `read_excel` function assigned these automatically. For our purposes, it is important that our result columns are numeric (`dbl` means "double wide" and is a type of numeric data format).

View imported data - 2
========================================================

In R-Studio, objects can also be _inspected_ using the "Environment" tab (usually in the top right pane). 

Exercise 2
=======================
Click on `afp`.

View imported data - 3
========================================================
class: small-code
A quick way to look at only the top `n` rows is using the `head` function:
```{r}
head(afp, n=3)      # top 3 rows
```
> <small>Comments: </small>
> <small> - Any text following a "#" is considered a "comment" in R, and **is not part of the code**. </small> 

Isolate an individual variable
========================================================

We can use the `$` shorthand to isolate _individual_ variable. Note that this is no longer a table, but just an array of values.
```{r}
afp$method_a
```

Examine data distribution
========================================================

Let's focus on the maternal serum AFP values from Method A first. 

```{r basic_stats}
mean(x = afp$method_a)  # Mean
median(x = afp$method_a) # Median
sd(x = afp$method_a) # Standard deviation
```

Exercise 3
========================================================
Using the functions `mean` and `sd`, write code that will calculate the Coefficient of Variation (CV) for the assay. 
- _Hint_: The CV is defined as:

\[
CV(\%) = \sigma/\mu * 100
\]

Is it normally distributed?
========================================================
There are many approaches to determining "normality" of a distribution. 
<small> 
- Calculation of mean, median, mode and SDs can help. 
- Visual inspection of the data will also quickly reveal if the data is normal, skewed, multimodal, etc. 
</small>

> Anscombe's quartet: Example of how summary statistics can mask true differences 
```{r, echo=FALSE, fig.align="center", out.width = "300px"}
knitr::include_graphics("https://d2f99xq7vri1nk.cloudfront.net/AllDinosGrey_1.png")
```
*https://www.autodeskresearch.com/publications/samestats*

ggplot: to visualize data
========================================================

> The idea of ggplot is to use graphical "building blocks" and combine them to create just about any kind of graphical display you want. 

```{r, fig.width=8, fig.height=6, fig.align='center'}
library(tidyverse)
ggplot(data=afp) +
  geom_histogram(bins=50, aes(x=method_a))
```

ggplot
========================================================
What's going on here? Take a look at this visual breakdown:

![](assets/ggplot_1.png)

Exercise 4
========================================================
1. Make a second histogram plotting `method_b` values. Select reasonable `binwidth` or `bins`.

``` {r, eval=FALSE}
ggplot(data=XXXXXXX) +
  geom_histogram(XXXXXXX, aes(x=XXXXXXXX))
```

``` {r, echo=FALSE}
ggplot(data=afp) +
  geom_histogram(binwidth = 10, aes(x=method_b))
```

Exercise 4.2
========================================================
2. Transform the x-axis to log-scale using `scale_x_log10` and visually inspect for normality

How can we quantify this?
========================================================

The **skew** and **kurtosis** are so-called **moments** of a distribution and can be used as measure of normality (or non-normality).

```{r}
library(moments)       # load the functions
skewness(afp$method_a)
kurtosis(afp$method_a)
```

Exercise 5
========================================================
Let's assess the `skewness` and `kurtosis` of the log-transformed method_a data. Use the `log10` function to transform results.

```{r, eval=FALSE}
method_a_logged <- XXXXXXXXXX
skewness(XXXXXXXXXXXX)

```

```{r, echo=FALSE}
method_a_logged <- log10(afp$method_a)
skewness(method_a_logged)
kurtosis(method_a_logged)
```

Tests for normality
========================================================
Another option is to use the **Shapiro-Wilk test of normality**:

```{r}
shapiro.test(afp$method_a)
shapiro.test(log(afp$method_a))
```

Establishing a reference range
========================================================

Reference ranges can be established in several different ways. Two of the most common approaches are termed **parametric** and **non-parametric**. 

| |Parametric|Non-parametric|
|:-------------|:-------------------------:|:-------------------------:|
|Good for|Normal distributions|Skewed, log-normal, or other non-normal distributions|
|Assumptions|Assumes normality|No assumptions about underlying distribution|
|Center of distribution|Mean|Median|
|Advantages|More power|Less affected by outliers, Simple to calculate|
|Disadvantages|Affected by outliers + skew|Less power, requires more samples|
|CLSI Recommended Approach|No|Yes|

Parametric Reference Ranges
========================================================

![](assets/rrange.png)

Where $\mu$ is the mean (average) of the distribution and $\sigma$ is the standard deviation.

Calculate parametric reference range for method_a
========================================================
class: small-code
```{r}
mu <- mean(afp$method_a)
sigma <- sd(afp$method_a)

lower_bound <- mu - 1.96 * sigma
upper_bound <- mu + 1.96 * sigma

sprintf("The reference range assuming normal distribution is (%3.1f, %3.1f)", 
        lower_bound, upper_bound)
```

Exercise 6
========================================================
class: small-code

Calculate the parametric reference range assuming that the results are log-normal (rather than normally distributed). 
- *Hint:* First transform the data as above with the `log()` function, and then "untransform" back into real numbers with `exp()`

```{r, eval=FALSE}
mu <- mean(______________)
sigma <- sd(______________)

lower_bound_transformed <- mu - 1.96 * sigma
upper_bound_transformed <- mu + 1.96 * sigma

lower_bound_untransformed <- ______________________
upper_bound_untransformed <- _____________________

sprintf("The reference range assuming log-normal distribution is (%3.1f, %3.1f)", 
        lower_bound_untransformed, upper_bound_untransformed)
```

```{r, echo=FALSE}
mu <- mean(log(afp$method_a))
sigma <- sd(log(afp$method_a))

lower_bound_transformed <- mu - 1.96 * sigma
upper_bound_transformed <- mu + 1.96 * sigma

lower_bound_untransformed <- exp(lower_bound_transformed)
upper_bound_untransformed <- exp(upper_bound_transformed)

sprintf("The reference range assuming log-normal distribution is (%3.1f, %3.1f)", lower_bound_untransformed, upper_bound_untransformed)
```

Visually inspect proposed reference intervals
========================================================
class: small-code
- Start with with the code for the histogram above
- Add lines using the `geom_vline` function of ggplot.
```{r, fig.width=8, fig.height=2, fig.align="center"}
# Code from exercise answer above
mu <- mean(log(afp$method_a))
sigma <- sd(log(afp$method_a))
lower_bound_transformed <- mu - 1.96 * sigma
lower_bound_untransformed <- exp(lower_bound_transformed)

# new code to plot
ggplot(data=afp) +
  geom_histogram(bins=50, aes(x=method_a)) +
  geom_vline(xintercept=lower_bound_untransformed, color="blue")
```

Exercise 7
========================================================
class: small-code
- Add the additional 3 bounds we have just calculated to this plot. 
- Change to a dashed line by specifying `linetype` in the `geom_vline` function.

```{r, eval=FALSE}
g <- ggplot(data=afp) +
  geom_histogram(bins=50, aes(x=method_a)) +
  geom_vline(xintercept=lower_bound_untransformed, ___________, color="blue") +
  geom_vline(_____________) +
  geom_vline(_____________) +
  geom_vline(_____________)
g
```

```{r, echo=FALSE, fig.height=2, fig.width=8, fig.align="center"}
g <- ggplot(data=afp) +
  geom_histogram(bins=50, aes(x=method_a)) +
  geom_vline(xintercept=lower_bound_untransformed, linetype=3, color="blue") +
  geom_vline(xintercept=upper_bound_untransformed, linetype=3, color="blue") +
  geom_vline(xintercept=lower_bound, linetype=3, color="red") +
  geom_vline(xintercept=upper_bound, linetype=3, color="red")
g
```

Non-parametric Reference Ranges
===============================
class:small-code

Central 95% of the distribution

```{r}
non_parametric_bounds <- quantile(x=afp$method_a, 
                                  probs = c(0.025, 0.975))
print(non_parametric_bounds)
```


> Can we verify that the `non_parametric_bounds` includes 95% of the data? 

Refer to element of vector elements
==================================================
class:small-code
```{r}
non_parametric_bounds
non_parametric_bounds[1]
non_parametric_bounds[[1]]
non_parametric_bounds[["2.5%"]]
```

Evaluate reference range - 1
==================================================
class: small-code
Let's first ask which elements of `method_a` are greater than our lower-bound?
```{r}
mask <- afp$method_a > non_parametric_bounds[[1]]
mask
```

The result is a boolean (TRUE/FALSE) array. 

Evaluate reference range - 2
==================================================
class: small-code
Then lets combine our upper and lower bounds
```{r}
mask <- (afp$method_a > non_parametric_bounds[[1]]) & 
                (afp$method_a < non_parametric_bounds[[2]])
mask[1:10]
```

Evaluate reference range - 3
==================================================
class: small-code

```{r}
mask <- (afp$method_a > non_parametric_bounds[[1]]) & 
                (afp$method_a < non_parametric_bounds[[2]])
length(mask)
sum(mask == TRUE)
proportion_in_range = sum(mask == TRUE) / length(mask)
print(proportion_in_range)

#Alternative
sum(mask) / length(mask)
```

Exercise 8:
=======================
Plot these proposed reference intervals on histogram

```{r, eval=FALSE}
ggplot(data=afp) + 


```

```{r, echo=FALSE, fig.height=3, fig.width=8, fig.align="center"}
ggplot(data=afp) +
  geom_histogram(bins=50, aes(x=method_a)) +
  geom_vline(xintercept = non_parametric_bounds["2.5%"], color="red", linetype=3) +
  geom_vline(xintercept = non_parametric_bounds["97.5%"], color="red", linetype=3)
```

How to verify a proposed reference range?
========================================
class: small-code
```{r, echo=FALSE, fig.height=2, fig.width=8, fig.align="center"}
ggplot(data=afp) +
  geom_histogram(bins=50, aes(x=method_a)) +
  geom_vline(xintercept = 20, color="red", linetype=3) +
  geom_vline(xintercept = 100, color="red", linetype=3)
```

```{r}
n_samples <- length(afp$method_a)

old_range <- c(20, 100) #proposed range
n_inrange <- sum(afp$method_a >= old_range[1] & 
                   afp$method_a <= old_range[2])s

chisq.test(c(n_inrange, n_samples - n_inrange), 
           p=c(0.95, 0.05))
```

How to verify a proposed reference range?
========================================
class: small-code
```{r, echo=FALSE, fig.height=2, fig.width=8, fig.align="center"}
ggplot(data=afp) +
  geom_histogram(bins=50, aes(x=method_a)) +
  geom_vline(xintercept = 20, color="red", linetype=3) +
  geom_vline(xintercept = 100, color="red", linetype=3)
```

```{r}
binom.test(x=n_inrange, n=n_samples, 
           p = 0.95, alternative = "two.sided")
```

Exercise 9
==================

Evaluate our empirically derived parametric reference ranges

Done!!
================
