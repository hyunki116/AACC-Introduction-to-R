Method Validation in R -- Method Comparison
========================================================
author: Niklas Krumm, Daniel S. Herman
date: July 2018
autosize: true
css: assets/custom.css

Overview
========================================================
In this section we will continue exploring how to use R in method validation by comparing results from two different methods.

Load data
========================================================
Let's load in hCG data, just as we did in the previous session.

```{r load_data_1}
library(tidyverse)
library(readxl)
hcg <- read_excel(path="data/Method_Validation.data.xlsx", 
                sheet="MS HCG")
glimpse(hcg)
```

Describe data and explore its distribution
========================================================
Let's use pipes to summarize and calculate a few statistics:

```{r}
hcg %>%
  summarize(method_a_mean = mean(method_a), 
            method_a_sd = sd(method_a),
            method_b_mean = mean(method_b), 
            method_b_sd = sd(method_b))
```

How to visualize multiple distributions?
========================================================
What if we want to plot the distribution of both `method_a` and `method_b` in the same plot? 
- We've used `geom_histogram` previously. 
- Let's try the related ggplot function `geom_freqpoly`, starting with a single method.

```{r}
ggplot(data = hcg) + 
  geom_freqpoly(bins=20, aes(x=method_a))
```

Overlapping histograms
========================================================
Now, let's add a second method and mark the two using `geom_freqpoly`.

```{r}
ggplot(data = hcg) + 
  geom_freqpoly(bins=20, aes(x=method_a, color="blue")) +
  geom_freqpoly(bins=20, aes(x=method_b, color="red")) 
```

Exercise 1
========================================================
Make a similar display of method a and method b distributions using the `geom_density` function. 
- Set the `fill` and `color` functions to distinguish between the two methods. 
- Test using the `alpha` parameter to increase the shape translucency

```{r, eval=FALSE}
ggplot(data = hcg) + 
  
  
```

```{r, echo=FALSE}
ggplot(data = hcg) + 
  geom_density(aes(x=method_a, fill="blue", color="blue"), alpha=0.5) +
  geom_density(aes(x=method_b, fill="red", color="red"), alpha=0.5)

```

Method comparison (t-tests, and more)
===========================

Using a statistical test
===========================
class: small-code
R is a statistical programming language, so simple statistical testing is straightforward:
```{r}
t.test(hcg$method_a, hcg$method_b, 
       paired=TRUE)    # Note we are using the paired=TRUE, since we have paired measurements.
```

Exercise 2
==========================
Evaluate parametric comparability of method means after log-transformation

```{r, eval=FALSE}
# Note we are using the paired=TRUE variant of the t.test, since we have paired measurements.
t.test(___________, ____________, 
       paired=TRUE)
```

```{r, echo=FALSE}
# Note we are using the paired=TRUE variant of the t.test, since we have paired measurements.
t.test(log(hcg$method_a), log(hcg$method_b), 
       paired=TRUE)
```

Using the RIGHT statistical test
====================================
- Is `t.test` the right function? 
- Consider the histograms above and our previous work with log normalizing the values. 

|Populations|Parametric|Non-parametric|
|:-------------|:-------------------------:|:-------------------------:|
|Two populations|t-test|Mann-Whitney U|
|Many populations|ANOVA|Kruskal Wallis / one-way anova|
|Populations across several treatments/times|repeated measures ANOVA|Friedman test|

Exercise 3
====================================
Using the table below, select the _right_ test for comparing `method_a` and `method_b` and assess.

|Populations|Parametric|Non-parametric|
|:-------------|:-------------------------:|:-------------------------:|
|Two populations|t-test|Mann-Whitney U|
|Many populations|ANOVA|Kruskal Wallis / one-way anova|
|Populations across several treatments/times|repeated measures ANOVA|Friedman test|

```{r, eval=FALSE}
hcg %>%
  
```

```{r, echo=FALSE}
sprintf("P-value: %3.2g", 
        wilcox.test(hcg$method_a, hcg$method_b, paired=TRUE)$p.value)
```

Regression
====================================

Visualize x & y results
====================================
Let's begin by simply plotting `method_a` and `method_b` as a scatter plot. 
- Notice how we are using the `aes()` to define "mappings" from our data to the x and y coordinates:
```{r}
ggplot(data=hcg) + 
  geom_point(aes(x=method_a, y=method_b))
```

Simple linear regression
====================================
Adding a least-squares regression line is easy with a little bit of magic from `ggplot`. 
- The `lm` (Linear Model) function does all the work here!

```{r}
ggplot(hcg) + 
  geom_point(aes(x=method_a, y=method_b)) + 
  geom_smooth(method = "lm", aes(x=method_a, y=method_b))
```

Simple linear regression - 2
====================================
It's tough to see the fit in the low result range, so we can transform our axis.

```{r}
ggplot(hcg) + 
  geom_point(aes(x=method_a, y=method_b)) + 
  geom_smooth(method = "lm", aes(x=method_a, y=method_b)) +
  scale_x_log10() + scale_y_log10()
```

Linear fit coefficients
=================================
class: small-code
What if we want to just extract the coefficients of the linear model? 
- We can utilize R's formula notation format and the `lm` function:

```{r}
regression <- lm(method_b ~ method_a, hcg)
summary(regression)
coef(regression)
```

Deming regression
==================================
class: small-code
- Considers measurement error in x- and y-axes

```{r}
library(mcr)    
deming_results <- mcreg(hcg$method_a, hcg$method_b, 
                        method.reg = "Deming")
deming_results@para         # "para" short for "parameters" (take a `glimpse` at `deming_results`)
```

Exercise 4
=======================
What if the fit is not perfectly linear, but slightly different in the low versus high range?
Let's use the weighted deming method of the `mcreg` function, to explore one way of balancing the effect of error throughout the result range.

```{r, eval=FALSE}
wdeming_results <- __________________
wdeming_results@para         
```

```{r, echo=FALSE}
wdeming_results <- mcreg(hcg$method_a, hcg$method_b, 
                        method.reg = "WDeming")
wdeming_results@para         
```

Compare multiple regression fits - 1
================================
Now let's add the lines to our plot using `geom_abline()` 
- The intercept and slope are stored in `deming_results@para[1]` and `deming_results@para[2]`, respectively.

```{r}
ggplot(hcg) +
  geom_point(aes(x=method_a, y=method_b))  +
  geom_smooth(method = "lm", aes(x=method_a, y=method_b), se=FALSE) +
  geom_abline(intercept = deming_results@para[1], slope = deming_results@para[2], color="red")
```

Compare multiple regression fits - 2
================================
class:small-code
- What about the weighted deming fit line? What about the subrange between 0 and 40000? 
- Let's also add a 1:1 line to help interpret fit.

```{r}
ggplot(hcg) +
  geom_point(aes(x=method_a, y=method_b))  +
  geom_smooth(method = "lm", aes(x=method_a, y=method_b), se=FALSE) +   #blue
  geom_abline(intercept = deming_results@para[1], slope = deming_results@para[2], color="red") +
  geom_abline(intercept = wdeming_results@para[1], slope = wdeming_results@para[2], color="yellow") +
  xlim(0, 40000) + ylim(0, 40000) +
  geom_abline(intercept=0, slope=1, linetype=2, color="gray")
```

Passing-Bablock
=================================
- Non-parametric regression

```{r}
PB_results <- mcreg(hcg$method_a, hcg$method_b, method.reg = "PaBa")
PB_results@para
```

Exercise 5
================================
class: small-code
Add another `geom_abline` to the plot above for the Passing-Bablock regression coefficients determined above.

```{r, eval=FALSE}
ggplot(hcg) +
  geom_point(aes(x=method_a, y=method_b))  +
  geom_smooth(method = "lm", aes(x=method_a, y=method_b), se=FALSE) +  #blue
  geom_abline(intercept = deming_results@para[1], slope = deming_results@para[2], color="red") +
  xlim(0, 40000) + ylim(0, 40000) +
  geom_abline(intercept=0, slope=1, linetype=2, color="gray") +
  geom_abline(____________________)
```

```{r, echo=FALSE}
ggplot(hcg) +
  geom_point(aes(x=method_a, y=method_b))  +
  geom_smooth(method = "lm", aes(x=method_a, y=method_b), se=FALSE) +  #blue
  geom_abline(intercept = deming_results@para[1], slope = deming_results@para[2], color="red") +
  xlim(0, 40000) + ylim(0, 40000) +
  geom_abline(intercept=0, slope=1, linetype=2, color="gray") +
  geom_abline(intercept = PB_results@para[1], slope = PB_results@para[2], color="yellow")
```

Extra-credit: Outlier robustness
===============================
class: small-code
How "robust" are each of these methods to outliers? Let's try it out.
```{r}
# Step 1: make a copy of the data so we don't change the original
hcg_with_outliers <- hcg

# Step 2: modify the data to include some outliers for method_a (fake data!)
hcg_with_outliers$method_a[10:12] <- 100000

# Step 3: Re-run fits
deming_results_outliers <- mcreg(hcg$method_a, hcg$method_b, 
                        method.reg = "Deming")
PB_results_outliers <- mcreg(hcg$method_a, hcg$method_b, method.reg = "PaBa")

# Step 3: same plotting code as above, using our new fake data
ggplot(hcg_with_outliers) +
  geom_point(aes(x=method_a, y=method_b))  +
  geom_smooth(method = "lm", aes(x=method_a, y=method_b), se=FALSE) +   #blue
  geom_abline(intercept = deming_results_outliers@para[1], slope = deming_results_outliers@para[2], color="red") +
  geom_abline(intercept = PB_results_outliers@para[1], slope = PB_results_outliers@para[2], color="green")

```

Compare methods by concordance relative to decision thresholds
==================================
Next, let's compare method A and B using decision thresholds. 
- For the purpose of this tutorial, we will simply use 25,000 as our threshold.

```{r}
threshold <- 25000

tmp <- hcg %>%
  mutate(method_a_pos = method_a > threshold,   # Create binary indicator for method_a
         method_b_pos = method_b > threshold)
table(x=tmp$method_a_pos, y=tmp$method_b_pos)
```

_Method_a and method_b are *discordant* across our threshold in 40 cases, and *concordant* in 58 + 48 cases_

Compare methods by concordance relative to decision thresholds
==================================
A tidy way to do this without using `tmp` and `table` is:

```{r}
threshold <- 25000

hcg %>%
  mutate(method_a_pos = method_a > threshold,   # Create binary indicator for method_a
         method_b_pos = method_b > threshold) %>%
  count(method_a_pos, method_b_pos)
```

Compare methods by concordance relative to decision thresholds
==================================
class: small-code
Now to convert this into a standard concordance table:

```{r}
hcg %>%
  mutate(method_a_pos = method_a > threshold,   # Create method_a binary indicator
         method_b_pos = method_b > threshold) %>%
  count(method_a_pos, method_b_pos)  %>%
  spread(method_b_pos, n, fill=0, sep=".")   # Spreads method_b_pos from one variable to multiple
```

Exercise 6
======================
Write code to compare accuracy across two different decision thresholds (25000 and 50000, for example)

_Hint #1_: In the `mutate` function, use the `cut()` function to break a numerical range into multiple a set of factor levels (categories):
     For instance, for method_a you could run `cut(hcg$method_a, breaks=c(0, 20, 40, Inf), labels=c("low","middle","high"))` to convert to a factor for 0-20, 20-40, 40-Inf.

_Hint #2_: Look at previous code for inspiration!

```{r, eval=FALSE}
hcg %>%
  mutate(method_a_bin = ________________________________,   # Create method_a factor
         method_b_bin = _________________________________) %>%
  count(method_a_bin, method_b_bin)  %>%
  spread(method_b_bin, n, fill=0, sep=".")   # Spreads method_b_pos from a one to multiple variables
```

```{r, echo=FALSE}
hcg %>%
  mutate(method_a_bin = cut(method_a, 
                            breaks=c(-Inf, 25000, 50000, Inf), 
                            labels=c("low","middle","high")),   # Create factor indicator for method_a
         method_b_bin = cut(method_b, 
                            breaks=c(-Inf, 25000, 50000, Inf), 
                            labels=c("low","middle","high"))) %>%
  count(method_a_bin, method_b_bin)  %>%
  spread(method_b_bin, n, fill=0, sep=".")   # Spreads method_b_pos from a single variable to a variable for each value
```

Done!!
=====================